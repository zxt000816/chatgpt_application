{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks import get_openai_callback\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.indexes import VectorstoreIndexCreator\n",
    "\n",
    "# index = VectorstoreIndexCreator(\n",
    "#     vectorstore_kwargs={\"persist_directory\": save_path},\n",
    "# ).from_loaders([loader])\n",
    "\n",
    "# index.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader('./data/小说.txt')\n",
    "\n",
    "save_path = 'novel' # db\n",
    "\n",
    "# text_splitter = CharacterTextSplitter(separator = \"\\n\", chunk_size=300, chunk_overlap=0)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(loader.load())\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "db = Chroma.from_documents(texts, embeddings, persist_directory=save_path)\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=OpenAI(temperature=0), chain_type=\"stuff\", retriever=retriever)\n",
    "query = \"张小凡使用什么方式打败了鬼王？\"\n",
    "\n",
    "qa.run(query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "reader = PdfReader('./data/1705.07750.pdf')\n",
    "# read data from the file and put them into a variable called raw_text\n",
    "raw_text = ''\n",
    "for i, page in enumerate(reader.pages):\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        raw_text += text\n",
    "\n",
    "print(len(raw_text))  \n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "texts = text_splitter.split_text(raw_text)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "docsearch = FAISS.from_texts(texts, embeddings)\n",
    "\n",
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"stuff\")\n",
    "\n",
    "query = \"who are the authors of the article?\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with another strategy.\n",
      "Falling back to partitioning with ocr_only.\n",
      "Using embedded DuckDB with persistence: data will be stored in: cv_paper\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "sudo apt-get update\n",
    "sudo apt-get install tesseract-ocr\n",
    "\"\"\"\n",
    "\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "save_path = 'cv_paper'\n",
    "\n",
    "loader = UnstructuredPDFLoader('./data/1705.07750.pdf')\n",
    "pages = loader.load_and_split(RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0))\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "docsearch = Chroma.from_documents(pages, embeddings, persist_directory=save_path).as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"这篇文章主要的贡献有哪些\"\n",
    "docs = docsearch.get_relevant_documents(query)\n",
    "\n",
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"stuff\", verbose=True)\n",
    "\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    response = chain.run(input_documents=docs, question=query)\n",
    "    print(f\"Answer: {response}\\n\")\n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Successful Requests: {cb.successful_requests}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatgpt_app_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
